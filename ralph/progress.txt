# Ralph Progress Log
# Project: (awaiting assignment)
# Branch: (awaiting assignment)
# Started: 2026-01-29

## Codebase Patterns
- ConfigValidator uses dot-notation for nested key access (e.g., 'database.server')
- Default values are defined in module-level DEFAULTS dict
- Custom exceptions should include typed field lists for clear debugging
- All modules in src/common/ follow camelCase for functions, PascalCase for classes
- Test files use AAA pattern (Arrange, Act, Assert) with descriptive docstrings
- Use relative imports within subpackages (e.g., `from .types import ...`)
- Use absolute imports across subpackages (e.g., `from src.obd.data.types import ...`)
- Types modules should have no dependencies on other project modules
- Consider using `TYPE_CHECKING` for type hints to avoid runtime circular imports

## Coding Rules (Mandatory)
1. **Write reusable code** - Extract common logic into shared utilities; check existing helpers before writing new ones
2. **Keep files small** - ~300 lines for source, ~500 lines for tests; split when exceeding
3. **Organize by functionality and module** - Group into packages with types.py, exceptions.py, core, helpers.py, __init__.py

## Working Rules
- PM communication: blockers -> pm/blockers/, tech debt -> pm/techDebt/, issues -> pm/issues/
- specs/ is **read-only** for Ralph; request PM for spec changes via pm/issues/
- pm/backlog/ is **PM-only**; Ralph does not write there
- Git branching: use sprint branches (e.g., sprint/2026-02-sprint1), merge to master when sprint is done
- Never push directly to master during active sprint work
- Single config file: src/obd_config.json (SQLite, Eclipse OBD-II project)
- Single requirements file: requirements.txt (includes dev tools); Pi-specific in requirements-pi.txt

## Project Structure Knowledge
- src/common/ - Foundation utilities (config_validator, secrets_loader, logging_config, error_handler)
- src/obd/ - OBD-II domain (orchestrator, connection, database, data, drive, vehicle, simulator, etc.)
- src/ai/ - AI analysis (analyzer, ollama manager)
- src/backup/ - Backup system (backup_manager, google_drive uploader)
- src/hardware/ - Raspberry Pi hardware (HardwareManager, UpsMonitor, ShutdownHandler, GpioButton, StatusDisplay)
- src/display/ - Display rendering (drivers/, adapters/)
- src/power/ - Power monitoring
- src/alert/ - Alert management
- src/analysis/ - Statistical analysis
- src/calibration/ - Calibration sessions
- src/profile/ - Profile management
- tests/ - Flat structure, all test_*.py files (no subdirectories for integration/e2e yet)
- pm/ - Project management (backlog, PRDs, issues, blockers, techDebt, roadmap)
- specs/ - Developer reference (standards, architecture, methodology, anti-patterns, glossary) - READ ONLY
- ralph/ - Agent system (agent.md, prd.json, progress.txt, ralph_agents.json, archive/)

## Known Tech Debt (filed as TD-001)
- orchestrator.py is 2,500 lines (CRITICAL - needs splitting)
- test_orchestrator.py is 7,516 lines (CRITICAL - needs splitting)
- 11 source files over 500 lines
- 3 empty placeholder packages: src/obd/export/, src/obd/shutdown/, src/obd/service/
- TestDataManager in test_utils.py has __init__ causing pytest warning
- obd_config.json has display 240x240 (should be 480x320) and realtimeDataDays 7 (should be 365)

## Orchestrator Deep Dive (2026-01-29)

### Structure: 2,500 lines, 1 god class, 70+ methods, 40+ instance vars, 12 component dependencies
### Supporting: ShutdownState enum, HealthCheckStats dataclass, 4 exception classes, 1 factory function

### 12 Responsibility Areas
1. Lifecycle (init/start/stop) - 500 lines
2. Signal handling (SIGINT/SIGTERM, double-Ctrl+C) - 100 lines
3. Main event loop (100ms tick, health checks) - 100 lines
4. Event routing (callbacks for readings, drives, alerts, analysis, profiles) - 400 lines
5. Connection recovery (exponential backoff, pause/resume data logger) - 350 lines
6. Health monitoring (stats, data rate, uptime) - 200 lines
7. Status reporting (component status, backup status) - 130 lines
8. Display updates (distributed across callbacks)
9. VIN decoding (first-connection query, NHTSA API) - 120 lines
10. Backup management (init, catchup, schedule, upload, cleanup) - 300 lines
11. Hardware integration (Pi-only, UPS, GPIO) - distributed
12. Config extraction (timeouts, intervals, parameters) - 90 lines

### Component Init Order (dependency chain)
Database -> ProfileManager -> Connection -> VinDecoder -> DisplayManager -> HardwareManager -> StatisticsEngine -> DriveDetector -> AlertManager -> DataLogger -> ProfileSwitcher -> BackupManager

### Shutdown Order (reverse)
BackupManager -> DataLogger -> AlertManager -> DriveDetector -> StatisticsEngine -> HardwareManager -> DisplayManager -> VinDecoder -> Connection -> ProfileSwitcher -> ProfileManager -> Database

### Data Flow
Reading: DataLogger -> Orchestrator._handleReading -> DisplayManager + DriveDetector + AlertManager
Drive: DriveDetector -> Orchestrator._handleDriveStart/End -> DisplayManager + external callback
Alert: AlertManager -> Orchestrator._handleAlert -> DisplayManager + HardwareManager + external
Analysis: StatisticsEngine -> Orchestrator._handleAnalysisComplete -> DisplayManager + external
Profile: ProfileSwitcher -> Orchestrator._handleProfileChange -> AlertManager + DataLogger

### Proposed 7-Module Split
- types.py (~100 lines): ShutdownState, HealthCheckStats, exceptions, constants
- core.py (~750 lines): ApplicationOrchestrator class, __init__, properties, getStatus, runLoop
- lifecycle.py (~400 lines): All _initialize*() and _shutdown*() methods
- connection_recovery.py (~350 lines): Reconnection logic, pause/resume
- event_router.py (~400 lines): Callback registration and all _handle*() methods
- backup_coordinator.py (~300 lines): Backup init, scheduling, upload
- health_monitor.py (~200 lines): Health checks, stats, data rate
- signal_handler.py (~100 lines): SIGINT/SIGTERM handling

### Good Patterns Found
- Graceful fallbacks (HARDWARE_AVAILABLE, BACKUP_AVAILABLE flags)
- Dependency-ordered init, reverse-order shutdown
- Timeout-based shutdown with force-exit
- Exponential backoff for reconnection
- Double-Ctrl+C pattern (graceful then force)
- Non-critical errors logged as warnings, don't crash

### Concerning Patterns Found
- God class (2,500 lines, 12 deps, 40+ vars, 70+ methods)
- Component types are Optional[Any] - loses type safety
- 30+ hasattr() calls for duck typing instead of protocols/ABCs
- Threading without full coordination (daemon flag relied on)
- Callback chains hard to trace (reading triggers 4 handlers)
- Some magic numbers inline (0.1 sleep interval)

## Lessons Learned
- When changing config defaults (like main.py --config default), always check for test assertions on that value
- Config files accumulate drift: the generic template (src/config.json) and the actual project config (obd_config.json) diverged completely - only keep one
- requirements-dev.txt with `-r requirements.txt` creates duplication headaches - single file is simpler
- Dead code detection: if a file references deleted files (run_all_tests.py -> run_tests_*.py), it's dead too
- Windows 8.3 short filenames (NDH6SA~M) can get accidentally committed - check for garbage files
- Specs drift from code faster than expected: 7 drift items found across 5 spec files after just a few weeks
- Always run full test suite before committing housekeeping changes
- When archiving completed PRDs, copy both prd.json AND progress.txt to preserve context
- Agent state (ralph_agents.json) gets stale - clear completed task IDs during housekeeping

## Session Log

## 2026-01-29 - Housekeeping Session
- Reviewed all specs (standards, architecture, methodology, anti-patterns, glossary)
- Filed 7 code drift issues to PM (pm/issues/002-specs-code-drift-report.md)
- Filed 3 new coding rules request to PM (pm/issues/001-new-coding-rules-request.md)
- Cleaned stale files: tests/run_all_tests.py (dead code), ralph/NDH6SA~M (garbage artifact)
- Cleaned stale agent state in ralph_agents.json
- Archived completed tech-debt PRD to ralph/archive/2026-01-26-tech-debt-cleanup/
- Consolidated config files: removed generic src/config.json and config.example.json, kept src/obd_config.json
- Consolidated requirements.txt and requirements-dev.txt into single requirements.txt
- Filed tech debt report to PM (pm/techDebt/TD-001-large-files-and-empty-packages.md)
---

## 2026-01-31 - US-DEP-001
User Story: Create Deploy Configuration File
- Created deploy/deploy.conf.example with PI_HOST, PI_USER, PI_PATH, PI_PORT variables
- Added deploy/deploy.conf to .gitignore (Project Specific section)
- Copied deploy.conf.example to deploy.conf as working copy
- All 1133 tests pass, no Python source changes so typecheck unaffected
- Files changed: deploy/deploy.conf.example (new), .gitignore (updated), ralph/stories.json, ralph/ralph_agents.json, ralph/progress.txt
- **Learnings for future iterations:**
  - deploy/ directory already has install-service.sh, uninstall-service.sh, eclipse-obd.service from previous Pi setup work
  - Shell script headers in this project use two styles: pi_setup.sh uses the full `################################################################################` style, install-service.sh uses `# ==============================================================================` style - both are acceptable
  - System python (Windows Store) doesn't have dev tools (mypy, ruff) - must use .venv python or `python -m pytest` which resolves via PATH
  - The venv pytest works via `cd project && python -m pytest tests/` but direct `.venv/Scripts/python` calls may require approval
---

## 2026-01-31 - US-DEP-002
User Story: Create Core Deploy Script
- Created scripts/deploy.sh: full rsync-over-SSH deploy script
- Reads config from deploy/deploy.conf (PI_HOST, PI_USER, PI_PATH, PI_PORT)
- SSH connectivity check with ConnectTimeout=5 before sync
- rsync with --delete flag, excludes .venv/, __pycache__/, .git/, *.pyc, data/, logs/, .env, node_modules/ plus .mypy_cache/, .pytest_cache/, .ruff_cache/, htmlcov/, .coverage
- Parses rsync --stats output for file count and transfer size summary
- Meaningful exit codes: 0=success, 1=config error, 2=SSH failure, 3=rsync failure
- Output style matches pi_setup.sh (colored log_info/log_warn/log_error, log_section headers)
- Standard file header per specs/standards.md (################################ style)
- Idempotent: safe to run multiple times, creates remote dir if missing
- All 1133 tests pass, no Python source changes so typecheck unaffected
- Files changed: scripts/deploy.sh (new), ralph/stories.json, ralph/ralph_agents.json, ralph/progress.txt
- **Learnings for future iterations:**
  - rsync --stats provides "Number of regular files transferred", "Total file size", "Total transferred file size" which can be parsed with grep
  - For MINGW64 compatibility, rsync paths work directly without conversion since Git Bash handles POSIX paths
  - ssh -o BatchMode=yes is useful for non-interactive SSH checks (fails immediately if key auth not set up)
  - ssh -o StrictHostKeyChecking=accept-new auto-accepts new hosts without interactive prompt
  - The deploy script reserves exit codes 4-6 for future stories (US-DEP-003 deps, US-DEP-004 service, US-DEP-005 smoke test)
  - Additional rsync excludes (.mypy_cache, .pytest_cache, etc.) were added beyond AC requirements to avoid syncing dev artifacts
---

## 2026-01-31 - US-DEP-003
User Story: Add Dependency Installation Step to Deploy Script
- Added install_dependencies() function to scripts/deploy.sh
- Creates Python venv on Pi if .venv/ doesn't exist (python3 -m venv .venv)
- Computes combined md5sum hash of requirements.txt + requirements-pi.txt locally
- Retrieves stored hash from Pi (.last-requirements-hash) and compares
- If hashes match: prints "Dependencies up to date" and skips pip install
- If hashes differ: runs pip install -r for both requirements files via SSH
- Parses pip output for "Successfully installed" count or "Requirement already satisfied" count
- Saves updated hash to Pi after successful install
- Exits with code 4 on pip install failure or venv creation failure
- Added EXIT_DEPS_FAILURE=4 constant and REQUIREMENTS_HASH_FILE constant
- Updated modification history in file header
- All 1133 tests pass, no Python source changes so typecheck unaffected
- Files changed: scripts/deploy.sh (updated), ralph/stories.json, ralph/ralph_agents.json, ralph/progress.txt
- **Learnings for future iterations:**
  - md5sum on MINGW64/Git Bash works natively (no need for special handling)
  - Combining multiple files into a single hash via `cat file1 file2 | md5sum` is cleaner than hashing individually
  - pip's "Successfully installed" line lists all packages space-separated, so NF-2 gives the count (minus "Successfully" and "installed")
  - The hash file (.last-requirements-hash) is stored on the Pi at PI_PATH root, not in deploy/ directory, since it's a remote-side artifact
  - ssh commands with complex shell pipelines need careful quoting - single quotes inside double quotes work for remote paths
---

## 2026-01-31 - US-DEP-004
User Story: Add Service Restart Step to Deploy Script
- Added restart_service() function to scripts/deploy.sh
- Checks if eclipse-obd service is installed on Pi via `systemctl list-unit-files` + grep -c
- If service exists: restarts via `sudo systemctl restart eclipse-obd`
- If service not installed: skips gracefully, prints instruction to run deploy/install-service.sh
- Waits 3 seconds after restart, then checks status via `systemctl is-active`
- Reports service state: active (success), failed (exit 5), or unknown (warning)
- Added EXIT_SERVICE_FAILURE=5, SERVICE_NAME, SERVICE_WAIT_SECONDS constants
- Updated modification history in file header
- All 1133 tests pass, no Python source changes so typecheck unaffected
- Files changed: scripts/deploy.sh (updated), ralph/stories.json, ralph/ralph_agents.json, ralph/progress.txt
- **Learnings for future iterations:**
  - `systemctl is-active <service>` returns a single word: "active", "inactive", "failed", "activating" - cleanest way to check service state
  - `systemctl list-unit-files <service>.service` with grep -c is more reliable than `systemctl status` for checking if a service is installed (status returns non-zero for inactive services)
  - The Pi user needs passwordless sudo for systemctl restart - this is typically configured in /etc/sudoers.d/ during initial Pi setup
  - The existing deploy/install-service.sh and deploy/eclipse-obd.service files provide the full service installation context
  - Exit code 5 was already reserved by US-DEP-002 notes for this story
---

## 2026-01-31 - US-DEP-005
User Story: Add Post-Deploy Smoke Test
- Added smoke_test() function to scripts/deploy.sh
- Runs `python src/main.py --dry-run` on Pi via SSH (activates venv first with `. .venv/bin/activate`)
- Checks SSH command exit code: 0 = PASS, non-zero = FAIL
- On failure: prints smoke test output, then last 20 lines of service journal via `sudo journalctl -u eclipse-obd -n 20 --no-pager`
- Added print_summary() replacing old print_result(): shows comprehensive deployment summary with files synced, deps status, service status, smoke test result
- Added deployment tracking variables (SUMMARY_FILES_SYNCED, SUMMARY_DEPS_STATUS, SUMMARY_SERVICE_STATUS, SUMMARY_SMOKE_STATUS) set by each stage function
- Summary prints even on smoke test failure (before exit code 6)
- Added EXIT_SMOKE_FAILURE=6 constant
- Updated file header modification history
- All 1133 tests pass, no Python source changes so typecheck unaffected
- Files changed: scripts/deploy.sh (updated), ralph/stories.json, ralph/ralph_agents.json, ralph/progress.txt
- **Learnings for future iterations:**
  - `set -e` in bash means the `if ssh ...; then` pattern is needed for capturing exit codes - direct `ssh ... ; exitCode=$?` would cause the script to exit on non-zero
  - When capturing SSH output for both display and analysis, `> tmpfile 2>&1` is cleaner than `| tee tmpfile` for the smoke test since we only want to show output on failure
  - The venv activation (`. .venv/bin/activate`) must happen in the same SSH command as the python invocation since each SSH command is a separate shell
  - `sudo journalctl` may not be available or may have no logs if the service was never installed - the `2>/dev/null || echo` fallback handles this
  - Global shell variables (SUMMARY_*) are the simplest way to pass state between functions in bash for the deployment summary - no need for return values or temp files
---
